{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/NotebookVM/how-to-use-azureml/deployment/production-deploy-to-aks/production-deploy-to-aks.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying the Best Performing Model to Azure Kubernetes Service (AKS)\n",
    "This notebook shows the steps for deploying a service: registering a model, creating an image, provisioning a cluster (one time action), and deploying a service to it. \n",
    "We then test and delete the service, image and model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "from azureml.core.compute import AksCompute, ComputeTarget\n",
    "from azureml.core.webservice import Webservice, AksWebservice\n",
    "from azureml.core.model import Model\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.19.0\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "print(azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get workspace\n",
    "Load existing workspace from the config file info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quick-starts-ws-134480\n",
      "aml-quickstarts-134480\n",
      "southcentralus\n",
      "81cefad3-d2c9-4f77-a466-99a7f541c7bb\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.workspace import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Environment\n",
    "Create an environment that the model will be deployed with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "scoring_env = Environment.from_conda_specification(\n",
    "    name=\"scoring-env\", file_path=\"./envs/conda_dependencies.yml\"\n",
    ")\n",
    "# use Azure's default docker image\n",
    "scoring_env.docker.base_image =\"mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20200821.v1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write the Entry Script\n",
    "Write the script that will be used to predict on your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile utils.py\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def reduce_mem(df):\n",
    "    \"\"\" Reduce memory \"\"\"\n",
    "    starttime = time.time()\n",
    "    numerics = [\"int16\", \"int32\", \"int64\", \"float16\", \"float32\", \"float64\"]\n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if pd.isnull(c_min) or pd.isnull(c_max):\n",
    "                continue\n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if (\n",
    "                    c_min > np.finfo(np.float16).min\n",
    "                    and c_max < np.finfo(np.float16).max\n",
    "                ):\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif (\n",
    "                    c_min > np.finfo(np.float32).min\n",
    "                    and c_max < np.finfo(np.float32).max\n",
    "                ):\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    print(\n",
    "        \"-- Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction),time spend:{:2.2f} min\".format(\n",
    "            end_mem,\n",
    "            100 * (start_mem - end_mem) / start_mem,\n",
    "            (time.time() - starttime) / 60,\n",
    "        )\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def unique_count(df, features):\n",
    "    \"\"\" perform a unique count for categorical features\"\"\"\n",
    "    for f in tqdm(features):\n",
    "        print(f)\n",
    "        map_dict = dict(zip(df[f].unique(), range(df[f].nunique())))\n",
    "        df[f] = df[f].map(map_dict)\n",
    "        df[f + \"_count\"] = df[f].map(df[f].value_counts())\n",
    "    df = reduce_mem(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import numpy\n",
    "import joblib\n",
    "from utils import reduce_mem, unique_count\n",
    "\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\" Perform brief data preprocessing for the incoming dataset object \"\"\"\n",
    "\n",
    "    # categorical feature unique count\n",
    "    categorical_cols = [\n",
    "        \"slot_id\",\n",
    "        \"adv_id\",\n",
    "        \"adv_prim_id\",\n",
    "        \"creat_type_cd\",\n",
    "        \"inter_type_cd\",\n",
    "        \"age\",\n",
    "        \"city\",\n",
    "        \"uid\",\n",
    "        \"dev_id\",\n",
    "        \"task_id\",\n",
    "    ]\n",
    "    df = unique_count(df, categorical_cols)\n",
    "    df = reduce_mem(df)\n",
    "\n",
    "    # drop engineered features\n",
    "    drop_fea = [\"pt_d\", \"communication_onlinerate\", \"uid\"]\n",
    "    df.drop(columns=drop_fea, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    model_path = os.path.join(os.getenv(\"AZUREML_MODEL_DIR\"), \"model.joblib\")\n",
    "    # deserialize the model file back into a sklearn model\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "\n",
    "# note you can pass in multiple rows for scoring\n",
    "def run(raw_data):\n",
    "    try:\n",
    "        data = json.loads(raw_data)[\"data\"]\n",
    "        data = preprocess_data(data)\n",
    "        result = model.predict_proba(data)[:, 1]\n",
    "        # you can return any data type as long as it is JSON-serializable\n",
    "        return result.tolist()\n",
    "    except Exception as e:\n",
    "        error = str(e)\n",
    "        return error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "move scripts into the source folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_folder = \"predict\"\n",
    "\n",
    "if script_folder not in os.listdir():\n",
    "    os.mkdir(script_folder)\n",
    "\n",
    "try:\n",
    "    shutil.move('score.py', script_folder)\n",
    "    shutil.move('utils.py', script_folder)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the InferenceConfig\n",
    "Create the inference config that will be used when deploying the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "inf_config = InferenceConfig(source_directory=script_folder, entry_script='score.py', environment=scoring_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Provision the AKS Cluster\n",
    "This is a one time setup. You can reuse this cluster for multiple deployments after it has been created. If you delete the cluster or the resource group that contains it, then you would have to recreate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# Choose a name for your AKS cluster\n",
    "aks_name = 'ctr-scoring' \n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    aks_target = ComputeTarget(workspace=ws, name=aks_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    # Use the default configuration (can also provide parameters to customize)\n",
    "    prov_config = AksCompute.provisioning_configuration()\n",
    "\n",
    "    # Create the cluster\n",
    "    aks_target = ComputeTarget.create(workspace = ws, \n",
    "                                    name = aks_name, \n",
    "                                    provisioning_configuration = prov_config)\n",
    "\n",
    "if aks_target.get_status() != \"Succeeded\":\n",
    "    aks_target.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeeded\n",
      "None\n",
      "CPU times: user 9.2 ms, sys: 293 µs, total: 9.49 ms\n",
      "Wall time: 93 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "try:\n",
    "    aks_target.wait_for_completion(show_output = True)\n",
    "    print(aks_target.provisioning_state)\n",
    "    print(aks_target.provisioning_errors)\n",
    "except:\n",
    "    print(aks_target.provisioning_state)\n",
    "    print(aks_target.provisioning_errors)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy web service to AKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "sample-deploy-to-aks"
    ]
   },
   "outputs": [],
   "source": [
    "# Set the web service configuration (using default here)\n",
    "aks_config = AksWebservice.deploy_configuration()\n",
    "\n",
    "# # Enable token auth and disable (key) auth on the webservice\n",
    "# aks_config = AksWebservice.deploy_configuration(token_auth_enabled=True, auth_enabled=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(ws, 'click-through-rate-predictions-HDrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "sample-deploy-to-aks"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running....\n",
      "Succeeded\n",
      "AKS service creation operation finished, operation \"Succeeded\"\n",
      "2021-01-12T04:04:07,965221386+00:00 - iot-server/run \n",
      "2021-01-12T04:04:07,967980688+00:00 - nginx/run \n",
      "2021-01-12T04:04:07,968031190+00:00 - gunicorn/run \n",
      "/usr/sbin/nginx: /azureml-envs/azureml_024d70955107dc728a9f6a15687a2651/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_024d70955107dc728a9f6a15687a2651/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_024d70955107dc728a9f6a15687a2651/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_024d70955107dc728a9f6a15687a2651/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_024d70955107dc728a9f6a15687a2651/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "2021-01-12T04:04:07,982542926+00:00 - rsyslog/run \n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2021-01-12T04:04:08,054172870+00:00 - iot-server/finish 1 0\n",
      "2021-01-12T04:04:08,055614823+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 19.9.0\n",
      "Listening at: http://127.0.0.1:31311 (12)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 41\n",
      "SPARK_HOME not set. Skipping PySpark Initialization.\n",
      "Initializing logger\n",
      "2021-01-12 04:04:08,754 | root | INFO | Starting up app insights client\n",
      "Starting up app insights client\n",
      "2021-01-12 04:04:08,754 | root | INFO | Starting up request id generator\n",
      "Starting up request id generator\n",
      "2021-01-12 04:04:08,754 | root | INFO | Starting up app insight hooks\n",
      "Starting up app insight hooks\n",
      "2021-01-12 04:04:08,754 | root | INFO | Invoking user's init function\n",
      "Invoking user's init function\n",
      "2021-01-12 04:04:09,070 | root | INFO | Users's init has completed successfully\n",
      "Users's init has completed successfully\n",
      "2021-01-12 04:04:09,072 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n",
      "Skipping middleware: dbg_model_info as it's not enabled.\n",
      "2021-01-12 04:04:09,072 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n",
      "Skipping middleware: dbg_resource_usage as it's not enabled.\n",
      "2021-01-12 04:04:09,073 | root | INFO | Scoring timeout setting is not found. Use default timeout: 3600000 ms\n",
      "Scoring timeout setting is not found. Use default timeout: 3600000 ms\n",
      "2021-01-12 04:04:14,384 | root | INFO | Swagger file not present\n",
      "Swagger file not present\n",
      "2021-01-12 04:04:14,385 | root | INFO | 404\n",
      "404\n",
      "127.0.0.1 - - [12/Jan/2021:04:04:14 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"-\"\n",
      "2021-01-12 04:04:14,555 | root | INFO | Swagger file not present\n",
      "Swagger file not present\n",
      "2021-01-12 04:04:14,555 | root | INFO | 404\n",
      "404\n",
      "127.0.0.1 - - [12/Jan/2021:04:04:14 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"curl/7.67.0\"\n",
      "2021-01-12 04:04:17,221 | root | INFO | Swagger file not present\n",
      "Swagger file not present\n",
      "2021-01-12 04:04:17,221 | root | INFO | 404\n",
      "404\n",
      "127.0.0.1 - - [12/Jan/2021:04:04:17 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"-\"\n",
      "2021-01-12 04:04:17,466 | root | INFO | Swagger file not present\n",
      "Swagger file not present\n",
      "2021-01-12 04:04:17,466 | root | INFO | 404\n",
      "404\n",
      "127.0.0.1 - - [12/Jan/2021:04:04:17 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"curl/7.67.0\"\n",
      "\n",
      "Healthy\n",
      "CPU times: user 296 ms, sys: 13.4 ms, total: 309 ms\n",
      "Wall time: 27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "aks_service_name ='ctr-prediction-service-1'\n",
    "\n",
    "aks_service = Model.deploy(workspace=ws,\n",
    "                           name=aks_service_name,\n",
    "                           models=[model],\n",
    "                           inference_config=inf_config,\n",
    "                           deployment_config=aks_config,\n",
    "                           deployment_target=aks_target)\n",
    "\n",
    "aks_service.wait_for_deployment(show_output = True)\n",
    "print(aks_service.get_logs())\n",
    "print(aks_service.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the web service using run method\n",
    "We test the web sevice by passing data.\n",
    "Run() method retrieves API keys behind the scenes to make sure that call is authenticated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'[0.441306768, 0.405676435]'\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "import os\n",
    "import ssl\n",
    "\n",
    "def allowSelfSignedHttps(allowed):\n",
    "    # bypass the server certificate verification on client side\n",
    "    if allowed and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):\n",
    "        ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "allowSelfSignedHttps(True) # this line is needed if you use self-signed certificate in your scoring service.\n",
    "\n",
    "data = [\n",
    "    {\n",
    "        \"uid\": 1391930,\n",
    "        \"task_id\": 3481,\n",
    "        \"adv_id\": 3984,\n",
    "        \"creat_type_cd\": 6,\n",
    "        \"adv_prim_id\": 150,\n",
    "        \"dev_id\": 17,\n",
    "        \"inter_type_cd\": 5,\n",
    "        \"slot_id\": 18,\n",
    "        \"spread_app_id\": 11,\n",
    "        \"tags\": 39,\n",
    "        \"app_first_class\": 4,\n",
    "        \"app_second_class\": 17,\n",
    "        \"age\": 7,\n",
    "        \"city\": 161,\n",
    "        \"city_rank\": 3,\n",
    "        \"device_name\": 65,\n",
    "        \"device_size\": 141,\n",
    "        \"career\": 9,\n",
    "        \"gender\": 2,\n",
    "        \"net_type\": 2,\n",
    "        \"residence\": 18,\n",
    "        \"his_app_size\": 6,\n",
    "        \"his_on_shelf_time\": 3,\n",
    "        \"app_score\": 2,\n",
    "        \"emui_dev\": 14,\n",
    "        \"list_time\": 10,\n",
    "        \"device_price\": 2,\n",
    "        \"up_life_duration\": 20,\n",
    "        \"up_membership_grade\": -1,\n",
    "        \"membership_life_duration\": -1,\n",
    "        \"consume_purchase\": 2,\n",
    "        \"communication_onlinerate\": \"0^1^2^3^4^5^6^7^8^9^10^11^12^13^14^15^16^17^18^19^20^21^22^23\",\n",
    "        \"communication_avgonline_30d\": 13,\n",
    "        \"indu_name\": 36,\n",
    "        \"pt_d\": 1,\n",
    "        \"uid_prev_1_day_ctr\": 0.0,\n",
    "        \"uid_prev_2_day_ctr\": 0.0,\n",
    "        \"uid_prev_3_day_ctr\": 0.0,\n",
    "        \"uid_prev_4_day_ctr\": 0.0,\n",
    "        \"uid_prev_5_day_ctr\": 0.0,\n",
    "        \"uid_prev_6_day_ctr\": 0.0,\n",
    "        \"task_id_prev_1_day_ctr\": 0.0,\n",
    "        \"task_id_prev_2_day_ctr\": 0.0,\n",
    "        \"task_id_prev_3_day_ctr\": 0.0,\n",
    "        \"task_id_prev_4_day_ctr\": 0.0,\n",
    "        \"task_id_prev_5_day_ctr\": 0.0,\n",
    "        \"task_id_prev_6_day_ctr\": 0.0,\n",
    "        \"adv_id_prev_1_day_ctr\": 0.0,\n",
    "        \"adv_id_prev_2_day_ctr\": 0.0,\n",
    "        \"adv_id_prev_3_day_ctr\": 0.0,\n",
    "        \"adv_id_prev_4_day_ctr\": 0.0,\n",
    "        \"adv_id_prev_5_day_ctr\": 0.0,\n",
    "        \"adv_id_prev_6_day_ctr\": 0.0,\n",
    "        \"adv_prim_id_prev_1_day_ctr\": 0.0,\n",
    "        \"adv_prim_id_prev_2_day_ctr\": 0.0,\n",
    "        \"adv_prim_id_prev_3_day_ctr\": 0.0,\n",
    "        \"adv_prim_id_prev_4_day_ctr\": 0.0,\n",
    "        \"adv_prim_id_prev_5_day_ctr\": 0.0,\n",
    "        \"adv_prim_id_prev_6_day_ctr\": 0.0,\n",
    "        \"spread_app_id_prev_1_day_ctr\": 0.0,\n",
    "        \"spread_app_id_prev_2_day_ctr\": 0.0,\n",
    "        \"spread_app_id_prev_3_day_ctr\": 0.0,\n",
    "        \"spread_app_id_prev_4_day_ctr\": 0.0,\n",
    "        \"spread_app_id_prev_5_day_ctr\": 0.0,\n",
    "        \"spread_app_id_prev_6_day_ctr\": 0.0,\n",
    "    },\n",
    "    {\n",
    "        \"uid\": 2220385,\n",
    "        \"task_id\": 3401,\n",
    "        \"adv_id\": 1766,\n",
    "        \"creat_type_cd\": 7,\n",
    "        \"adv_prim_id\": 156,\n",
    "        \"dev_id\": 56,\n",
    "        \"inter_type_cd\": 5,\n",
    "        \"slot_id\": 16,\n",
    "        \"spread_app_id\": 58,\n",
    "        \"tags\": 37,\n",
    "        \"app_first_class\": 4,\n",
    "        \"app_second_class\": 21,\n",
    "        \"age\": 7,\n",
    "        \"city\": 103,\n",
    "        \"city_rank\": 4,\n",
    "        \"device_name\": 38,\n",
    "        \"device_size\": 162,\n",
    "        \"career\": 9,\n",
    "        \"gender\": 2,\n",
    "        \"net_type\": 2,\n",
    "        \"residence\": 39,\n",
    "        \"his_app_size\": 14,\n",
    "        \"his_on_shelf_time\": 3,\n",
    "        \"app_score\": 2,\n",
    "        \"emui_dev\": 20,\n",
    "        \"list_time\": 4,\n",
    "        \"device_price\": 4,\n",
    "        \"up_life_duration\": 20,\n",
    "        \"up_membership_grade\": 1,\n",
    "        \"membership_life_duration\": -1,\n",
    "        \"consume_purchase\": 2,\n",
    "        \"communication_onlinerate\": \"7^8^9^10^11^12^13^14^15^16^17^18^19^20^21^22^23\",\n",
    "        \"communication_avgonline_30d\": 11,\n",
    "        \"indu_name\": 17,\n",
    "        \"pt_d\": 1,\n",
    "        \"uid_prev_1_day_ctr\": 0.0,\n",
    "        \"uid_prev_2_day_ctr\": 0.0,\n",
    "        \"uid_prev_3_day_ctr\": 0.0,\n",
    "        \"uid_prev_4_day_ctr\": 0.0,\n",
    "        \"uid_prev_5_day_ctr\": 0.0,\n",
    "        \"uid_prev_6_day_ctr\": 0.0,\n",
    "        \"task_id_prev_1_day_ctr\": 0.0,\n",
    "        \"task_id_prev_2_day_ctr\": 0.0,\n",
    "        \"task_id_prev_3_day_ctr\": 0.0,\n",
    "        \"task_id_prev_4_day_ctr\": 0.0,\n",
    "        \"task_id_prev_5_day_ctr\": 0.0,\n",
    "        \"task_id_prev_6_day_ctr\": 0.0,\n",
    "        \"adv_id_prev_1_day_ctr\": 0.0,\n",
    "        \"adv_id_prev_2_day_ctr\": 0.0,\n",
    "        \"adv_id_prev_3_day_ctr\": 0.0,\n",
    "        \"adv_id_prev_4_day_ctr\": 0.0,\n",
    "        \"adv_id_prev_5_day_ctr\": 0.0,\n",
    "        \"adv_id_prev_6_day_ctr\": 0.0,\n",
    "        \"adv_prim_id_prev_1_day_ctr\": 0.0,\n",
    "        \"adv_prim_id_prev_2_day_ctr\": 0.0,\n",
    "        \"adv_prim_id_prev_3_day_ctr\": 0.0,\n",
    "        \"adv_prim_id_prev_4_day_ctr\": 0.0,\n",
    "        \"adv_prim_id_prev_5_day_ctr\": 0.0,\n",
    "        \"adv_prim_id_prev_6_day_ctr\": 0.0,\n",
    "        \"spread_app_id_prev_1_day_ctr\": 0.0,\n",
    "        \"spread_app_id_prev_2_day_ctr\": 0.0,\n",
    "        \"spread_app_id_prev_3_day_ctr\": 0.0,\n",
    "        \"spread_app_id_prev_4_day_ctr\": 0.0,\n",
    "        \"spread_app_id_prev_5_day_ctr\": 0.0,\n",
    "        \"spread_app_id_prev_6_day_ctr\": 0.0\n",
    "    }\n",
    "]\n",
    "\n",
    "body = str.encode(json.dumps(data))\n",
    "\n",
    "deployed_webservice = Webservice(ws, 'ctr-prediction-service-1')\n",
    "url = deployed_webservice.scoring_uri\n",
    "api_key = deployed_webservice.get_keys()[0]\n",
    "\n",
    "headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key)}\n",
    "\n",
    "req = urllib.request.Request(url, body, headers)\n",
    "\n",
    "try:\n",
    "    response = urllib.request.urlopen(req)\n",
    "\n",
    "    result = response.read()\n",
    "    print(result)\n",
    "except urllib.error.HTTPError as error:\n",
    "    print(\"The request failed with status code: \" + str(error.code))\n",
    "\n",
    "    # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\n",
    "    print(error.info())\n",
    "    print(json.loads(error.read().decode(\"utf8\", 'ignore')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up\n",
    "Delete the service, image and model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 6.91 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "aks_service.delete()\n",
    "model.delete()"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "vaidyas"
   }
  ],
  "categories": [
   "how-to-use-azureml",
   "deployment",
   "production-deploy-to-aks"
  ],
  "kernelspec": {
   "display_name": "azure_machine_learning",
   "language": "python",
   "name": "azure_machine_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
